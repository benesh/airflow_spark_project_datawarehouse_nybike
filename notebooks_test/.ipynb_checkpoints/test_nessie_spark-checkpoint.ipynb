{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f513f406-5928-4473-b140-82c95d2a5c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.12\n"
     ]
    }
   ],
   "source": [
    "!python3 --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a2d4236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://minio:9000\n",
      "http://nessie:19120/api/v1\n",
      "s3a://warehouse/\n",
      "M1s2Sa2IecSYl6SR6n4W\n",
      "Kj6gSYsC1Q5MJ6VXWVW1S1m8eC8gPKxtLcOxB2wk\n",
      "s3a://sylver-warehouse/\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "\n",
    "\n",
    "## DEFINE SENSITIVE VARIABLES\n",
    "NESSIE_URI = os.environ.get(\"NESSIE_URI\") ## Nessie Server URI\n",
    "WAREHOUSE = os.environ.get(\"WAREHOUSE\") ## BUCKET TO WRITE DATA TOO\n",
    "WAREHOUSE_BRONZE = os.environ.get(\"WAREHOUSE_BRONZE\") ## BUCKET TO WRITE DATA TOO\n",
    "WAREHOUSE_SYLVER = os.environ.get(\"WAREHOUSE_SYLVER\") ## BUCKET TO WRITE DATA TOO\n",
    "WAREHOUSE_GOLD = os.environ.get(\"WAREHOUSE_GOLD\") ## BUCKET TO WRITE DATA TOO\n",
    "AWS_ACCESS_KEY_ID = os.environ.get(\"AWS_ACCESS_KEY_ID\") ## AWS CREDENTIALS\n",
    "AWS_SECRET_ACCESS_KEY = os.environ.get(\"AWS_SECRET_ACCESS_KEY\") ## AWS CREDENTIALS\n",
    "AWS_S3_ENDPOINT= os.environ.get(\"AWS_S3_ENDPOINT\") ## MINIO ENDPOINT\n",
    "\n",
    "\n",
    "print(AWS_S3_ENDPOINT)\n",
    "print(NESSIE_URI)\n",
    "print(WAREHOUSE)\n",
    "print(AWS_ACCESS_KEY_ID)\n",
    "print(AWS_SECRET_ACCESS_KEY)\n",
    "print(WAREHOUSE_SYLVER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7ea8a43-9c5e-4bd0-a0e2-019fcdf37fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS_REGION is used by Spark\n",
    "AWS_REGION=\"us-east-1\"\n",
    "# This must match if using minio\n",
    "MINIO_REGION=\"us-east-1\"\n",
    "# Used by pyIceberg\n",
    "AWS_DEFAULT_REGION=\"us-east-1\"\n",
    "# AWS Credentials (this can use minio credential, to be filled in later)\n",
    "AWS_ACCESS_KEY_ID=\"YRUl5sf7KF7WTVAAgTSO\"\n",
    "AWS_SECRET_ACCESS_KEY=\"gWIjs4ljGZJHcum9RlZtKTrL5La7FNWXZvwppm6L\"\n",
    "# If using Minio, this should be the API address of Minio Server\n",
    "AWS_S3_ENDPOINT=\"http://minio:9000\"\n",
    "# Location where files will be written when creating new tables\n",
    "WAREHOUSE=\"s3a://warehouse/\"\n",
    "# URI of Nessie Catalog\n",
    "NESSIE_URI=\"http://nessie:19120/api/v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1db1d774-5d1d-4fd1-afed-4a6e683ed4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### not use\n",
    "conf = (\n",
    "    pyspark.SparkConf()\n",
    "        .setAppName('app_name')\n",
    "        .set('spark.jars.packages','org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.5.0,org.projectnessie.nessie-integrations:nessie-spark-extensions-3.5_2.12:0.102.5,software.amazon.awssdk:bundle:2.20.131,software.amazon.awssdk:url-connection-client:2.20.131')\n",
    "        .set('spark.sql.extensions','org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions,org.projectnessie.spark.extensions.NessieSparkSessionExtensions')\n",
    "        .set('spark.sql.catalog.bronze', 'org.apache.iceberg.spark.SparkCatalog')\n",
    "        .set('spark.sql.catalog.bronze.uri', NESSIE_URI)\n",
    "        .set('spark.sql.catalog.bronze.ref', 'main')\n",
    "        .set('spark.sql.catalog.bronze.authentication.type', 'NONE')  # ✅ Move auth to \"bronze\" catalog\n",
    "        .set('spark.sql.catalog.bronze.catalog-impl', 'org.apache.iceberg.nessie.NessieCatalog')  # ✅ Use \"bronze\" prefix\n",
    "        .set('spark.sql.catalog.bronze.s3.path-style-access', 'true')  # ✅ Configure S3 for \"bronze\"\n",
    "        .set('spark.sql.catalog.bronze.s3.endpoint', AWS_S3_ENDPOINT)  # ✅ Fixed typo (no 's' at end)\n",
    "        .set('spark.sql.catalog.bronze.warehouse', WAREHOUSE)\n",
    "        .set('spark.sql.catalog.bronze.io-impl', 'org.apache.iceberg.aws.s3.S3FileIO')  # ✅ Use \"bronze\" prefix\n",
    "        .set('spark.hadoop.fs.s3a.access.key', AWS_ACCESS_KEY_ID)\n",
    "        .set('spark.hadoop.fs.s3a.secret.key', AWS_SECRET_ACCESS_KEY)\n",
    "        .set('spark.hadoop.fs.s3a.path.style.access','true')\n",
    "        .set('spark.hadoop.fs.s3a.impl', 'org.apache.hadoop.fs.s3a.S3AFileSystem')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "847dcef6-5174-4deb-b402-5ed9c3d5a640",
   "metadata": {},
   "outputs": [],
   "source": [
    "## base config\n",
    "conf = (\n",
    "    pyspark.SparkConf()\n",
    "        .setAppName('app_name')\n",
    "        .set('spark.jars.packages','org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.5.0,org.projectnessie.nessie-integrations:nessie-spark-extensions-3.5_2.12:0.102.5,software.amazon.awssdk:bundle:2.20.131,software.amazon.awssdk:url-connection-client:2.20.131')\n",
    "        .set('spark.sql.extensions','org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions,org.projectnessie.spark.extensions.NessieSparkSessionExtensions')\n",
    "        .set('spark.hadoop.fs.s3a.access.key', AWS_ACCESS_KEY_ID)\n",
    "        .set('spark.hadoop.fs.s3a.secret.key', AWS_SECRET_ACCESS_KEY)\n",
    "        .set('spark.hadoop.fs.s3a.path.style.access','true')\n",
    "        .set('spark.hadoop.fs.s3a.impl', 'org.apache.hadoop.fs.s3a.S3AFileSystem')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4bbfda89-462b-4332-adae-d995b75929bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.conf.SparkConf at 0x7fa338b5f370>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## config bronze\n",
    "\n",
    "conf.set('spark.sql.catalog.bronze', 'org.apache.iceberg.spark.SparkCatalog')\\\n",
    ".set('spark.sql.catalog.bronze.uri', NESSIE_URI)\\\n",
    ".set('spark.sql.catalog.bronze.ref', 'main')\\\n",
    ".set('spark.sql.catalog.bronze.authentication.type', 'NONE')\\\n",
    ".set('spark.sql.catalog.bronze.catalog-impl', 'org.apache.iceberg.nessie.NessieCatalog')\\\n",
    ".set('spark.sql.catalog.bronze.s3.path-style-access', 'true')\\\n",
    ".set('spark.sql.catalog.bronze.s3.endpoint', AWS_S3_ENDPOINT)\\\n",
    ".set('spark.sql.catalog.bronze.warehouse', WAREHOUSE_BRONZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f96f823-b83f-4ec0-bb2a-cd3f3353edf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.conf.SparkConf at 0x7fa35177d3c0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Sylver settings catalog\n",
    "\n",
    "conf.set('spark.sql.catalog.sylver', 'org.apache.iceberg.spark.SparkCatalog')\\\n",
    "    .set('spark.sql.catalog.sylver.uri',NESSIE_URI)\\\n",
    "    .set('spark.sql.catalog.sylver.ref', 'main')\\\n",
    "    .set('spark.sql.catalog.sylver.authentication.type', 'NONE')\\\n",
    "    .set('spark.sql.catalog.sylver.catalog-impl', 'org.apache.iceberg.nessie.NessieCatalog')\\\n",
    "    .set('spark.sql.catalog.sylver.s3.path-style-access', 'true')\\\n",
    "    .set('spark.sql.catalog.sylver.s3.endpoint',AWS_S3_ENDPOINT)\\\n",
    "    .set('spark.sql.catalog.sylver.warehouse',WAREHOUSE_BRONZE)\\\n",
    "    .set('spark.sql.catalog.sylver.io-impl', 'org.apache.iceberg.aws.s3.S3FileIO')\\\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1c7a61d9-2d3d-4063-a583-73ae25f72a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bronze settings catalog\n",
    "\n",
    "conf = (\n",
    "    pyspark.SparkConf()\n",
    "        .setAppName('app_name')\n",
    "        .set('spark.jars.packages','org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.5.0,org.projectnessie.nessie-integrations:nessie-spark-extensions-3.5_2.12:0.102.5,software.amazon.awssdk:bundle:2.20.131,software.amazon.awssdk:url-connection-client:2.20.131')\n",
    "        .set('spark.sql.extensions','org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions,org.projectnessie.spark.extensions.NessieSparkSessionExtensions')\n",
    "        .set('spark.sql.catalog.sylver', 'org.apache.iceberg.spark.SparkCatalog')\n",
    "        .set('spark.sql.catalog.sylver.uri',NESSIE_URI)\n",
    "        .set('spark.sql.catalog.sylver.ref', 'main')\n",
    "        .set('spark.sql.catalog.sylver.authentication.type', 'NONE')  # ✅ Move auth to \"bronze\" catalog\n",
    "        .set('spark.sql.catalog.sylver.catalog-impl', 'org.apache.iceberg.nessie.NessieCatalog')  # ✅ Use \"bronze\" prefix\n",
    "        .set('spark.sql.catalog.sylver.s3.path-style-access', 'true')  # ✅ Configure S3 for \"bronze\"\n",
    "        .set('spark.sql.catalog.sylver.s3.endpoint',AWS_S3_ENDPOINT)  # ✅ Fixed typo (no 's' at end)\n",
    "        .set('spark.sql.catalog.sylver.warehouse',WAREHOUSE_BRONZE)\n",
    "        .set('spark.sql.catalog.sylver.io-impl', 'org.apache.iceberg.aws.s3.S3FileIO')  # ✅ Use \"bronze\" prefix\n",
    "        .set('spark.hadoop.fs.s3a.access.key',AWS_ACCESS_KEY_ID)\n",
    "        .set('spark.hadoop.fs.s3a.secret.key',AWS_SECRET_ACCESS_KEY)\n",
    "        .set('spark.hadoop.fs.s3a.path.style.access','true')\n",
    "        .set('spark.hadoop.fs.s3a.impl', 'org.apache.hadoop.fs.s3a.S3AFileSystem')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9e9b5e28-3fe9-4756-ba38-f80d4f2de064",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sylver settings catalog\n",
    "\n",
    "conf = (\n",
    "    pyspark.SparkConf()\n",
    "        .setAppName('app_name')\n",
    "        .set('spark.jars.packages','org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.5.0,org.projectnessie.nessie-integrations:nessie-spark-extensions-3.5_2.12:0.102.5,software.amazon.awssdk:bundle:2.20.131,software.amazon.awssdk:url-connection-client:2.20.131')\n",
    "        .set('spark.sql.extensions','org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions,org.projectnessie.spark.extensions.NessieSparkSessionExtensions')\n",
    "        .set('spark.sql.catalog.sylver', 'org.apache.iceberg.spark.SparkCatalog')\n",
    "        .set('spark.sql.catalog.sylver.uri', NESSIE_URI)\n",
    "        .set('spark.sql.catalog.sylver.ref', 'main')\n",
    "        .set('spark.sql.catalog.sylver.authentication.type', 'NONE')  # ✅ Move auth to \"bronze\" catalog\n",
    "        .set('spark.sql.catalog.sylver.catalog-impl', 'org.apache.iceberg.nessie.NessieCatalog')  # ✅ Use \"bronze\" prefix\n",
    "        .set('spark.sql.catalog.sylver.s3.path-style-access', 'true')  # ✅ Configure S3 for \"bronze\"\n",
    "        .set('spark.sql.catalog.sylver.s3.endpoint', AWS_S3_ENDPOINT)  # ✅ Fixed typo (no 's' at end)\n",
    "        .set('spark.sql.catalog.sylver.warehouse', WAREHOUSE_SYLVER)\n",
    "        .set('spark.sql.catalog.sylver.io-impl', 'org.apache.iceberg.aws.s3.S3FileIO')  # ✅ Use \"bronze\" prefix\n",
    "        .set('spark.hadoop.fs.s3a.access.key', AWS_ACCESS_KEY_ID)\n",
    "        .set('spark.hadoop.fs.s3a.secret.key', AWS_SECRET_ACCESS_KEY)\n",
    "        .set('spark.hadoop.fs.s3a.path.style.access','true')\n",
    "        .set('spark.hadoop.fs.s3a.impl', 'org.apache.hadoop.fs.s3a.S3AFileSystem')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e27fdf3a-a6d4-4df7-bfa0-d56bd28459be",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gold settings catalog\n",
    "\n",
    "conf = (\n",
    "    pyspark.SparkConf()\n",
    "        .setAppName('app_name')\n",
    "        .set('spark.jars.packages','org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.5.0,org.projectnessie.nessie-integrations:nessie-spark-extensions-3.5_2.12:0.102.5,software.amazon.awssdk:bundle:2.20.131,software.amazon.awssdk:url-connection-client:2.20.131')\n",
    "        .set('spark.sql.extensions','org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions,org.projectnessie.spark.extensions.NessieSparkSessionExtensions')\n",
    "        .set('spark.sql.catalog.sylver', 'org.apache.iceberg.spark.SparkCatalog')\n",
    "        .set('spark.sql.catalog.sylver.uri', NESSIE_URI)\n",
    "        .set('spark.sql.catalog.sylver.ref', 'main')\n",
    "        .set('spark.sql.catalog.sylver.authentication.type', 'NONE')  # ✅ Move auth to \"bronze\" catalog\n",
    "        .set('spark.sql.catalog.sylver.catalog-impl', 'org.apache.iceberg.nessie.NessieCatalog')  # ✅ Use \"bronze\" prefix\n",
    "        .set('spark.sql.catalog.sylver.s3.path-style-access', 'true')  # ✅ Configure S3 for \"bronze\"\n",
    "        .set('spark.sql.catalog.sylver.s3.endpoint', AWS_S3_ENDPOINT)  # ✅ Fixed typo (no 's' at end)\n",
    "        .set('spark.sql.catalog.sylver.warehouse', WAREHOUSE_GOLD)\n",
    "        .set('spark.sql.catalog.sylver.io-impl', 'org.apache.iceberg.aws.s3.S3FileIO')  # ✅ Use \"bronze\" prefix\n",
    "        .set('spark.hadoop.fs.s3a.access.key', AWS_ACCESS_KEY_ID)\n",
    "        .set('spark.hadoop.fs.s3a.secret.key', AWS_SECRET_ACCESS_KEY)\n",
    "        .set('spark.hadoop.fs.s3a.path.style.access','true')\n",
    "        .set('spark.hadoop.fs.s3a.impl', 'org.apache.hadoop.fs.s3a.S3AFileSystem')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98faed3-7f60-4205-a835-fc0bfa3dcfc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "org.apache.iceberg#iceberg-spark-runtime-3.5_2.12 added as a dependency\n",
      "org.projectnessie.nessie-integrations#nessie-spark-extensions-3.5_2.12 added as a dependency\n",
      "software.amazon.awssdk#bundle added as a dependency\n",
      "software.amazon.awssdk#url-connection-client added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-10c0b760-6088-45f5-900f-0f4ea9468679;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.iceberg#iceberg-spark-runtime-3.5_2.12;1.5.0 in central\n",
      "\tfound org.projectnessie.nessie-integrations#nessie-spark-extensions-3.5_2.12;0.102.5 in central\n",
      "\tfound software.amazon.awssdk#bundle;2.20.131 in central\n",
      "\tfound software.amazon.eventstream#eventstream;1.0.1 in central\n",
      "\tfound software.amazon.awssdk#url-connection-client;2.20.131 in central\n",
      "\tfound software.amazon.awssdk#utils;2.20.131 in central\n",
      "\tfound org.reactivestreams#reactive-streams;1.0.3 in central\n",
      "\tfound software.amazon.awssdk#annotations;2.20.131 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.30 in central\n",
      "\tfound software.amazon.awssdk#http-client-spi;2.20.131 in central\n",
      "\tfound software.amazon.awssdk#metrics-spi;2.20.131 in central\n",
      ":: resolution report :: resolve 1052ms :: artifacts dl 37ms\n",
      "\t:: modules in use:\n",
      "\torg.apache.iceberg#iceberg-spark-runtime-3.5_2.12;1.5.0 from central in [default]\n",
      "\torg.projectnessie.nessie-integrations#nessie-spark-extensions-3.5_2.12;0.102.5 from central in [default]\n",
      "\torg.reactivestreams#reactive-streams;1.0.3 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.30 from central in [default]\n",
      "\tsoftware.amazon.awssdk#annotations;2.20.131 from central in [default]\n",
      "\tsoftware.amazon.awssdk#bundle;2.20.131 from central in [default]\n",
      "\tsoftware.amazon.awssdk#http-client-spi;2.20.131 from central in [default]\n",
      "\tsoftware.amazon.awssdk#metrics-spi;2.20.131 from central in [default]\n",
      "\tsoftware.amazon.awssdk#url-connection-client;2.20.131 from central in [default]\n",
      "\tsoftware.amazon.awssdk#utils;2.20.131 from central in [default]\n",
      "\tsoftware.amazon.eventstream#eventstream;1.0.1 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   11  |   0   |   0   |   0   ||   11  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-10c0b760-6088-45f5-900f-0f4ea9468679\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 11 already retrieved (0kB/31ms)\n",
      "25/04/17 10:25:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "## Start Spark Session\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "# print(\"Spark Running\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "68d4e7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e044ba6-0f22-4d4d-b559-fe1596842d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e8332c45-5c3c-4c6e-b600-e06dc3279389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://minio:9000\n"
     ]
    }
   ],
   "source": [
    "print(spark.conf.get('spark.sql.catalog.nessie.s3.endpoint'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "7d022875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|      namespace|\n",
      "+---------------+\n",
      "|     DW_ny_bike|\n",
      "|SylverDw_nybike|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Create a Table\n",
    "spark.sql(\"show databases in bronze;\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c3f56016-399a-49ce-a1bf-a18d170a0664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create a Table\n",
    "spark.sql(\" CREATE DATABASE bronze.SylverDw_nybike;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c3265b6-3301-48cd-8be9-420b7c99ee90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create a Table\n",
    "spark.sql(\" CREATE DATABASE IF NOT EXISTS sylver.DW_ny_bike;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "9cf18acb-7e6b-4ac3-a04a-73b2c7fdf11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"show table bronze.SylverDw_nybike;\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "35cc5f47-e8b0-4cd3-a19b-35e1d7b34d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"DROP TABLE bronze.SylverDw_nybike.trip_data_nybike;\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ee6124f-990c-418f-baab-b707aabda202",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\n",
      "SLF4J: Defaulting to no-operation (NOP) logger implementation\n",
      "SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                 key|               value|\n",
      "+--------------------+--------------------+\n",
      "| current-snapshot-id| 5479237530675047789|\n",
      "|              format|     iceberg/parquet|\n",
      "|      format-version|                   2|\n",
      "|          gc.enabled|               false|\n",
      "|    nessie.commit.id|5133ffd6f336e8366...|\n",
      "|write.metadata.de...|               false|\n",
      "|write.parquet.com...|                zstd|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# spark.sql(\"show tables in nessie.dw_nybike;\").show()\n",
    "spark.sql(\"SHOW TBLPROPERTIES bronze.SylverDw_nybike.trip_data_nybike;\").show()\n",
    "# spark.sql(\"SELECT * FROM nessie.dw_nybike.trip_data_nybike_v2.snapshots;\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e6de411a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE TABLE bronze.DW_ny_bike.trip_data_nybike(\n",
    "    dw_period_tag string,\n",
    "    ride_id string,\n",
    "\tstart_station_id string,\n",
    "\tstart_station_name string,\n",
    "\tstart_station_latitude string ,\n",
    "\tstart_station_longitude string ,\n",
    "\tend_station_id string,\n",
    "\tend_station_name string,\n",
    "\tend_station_latitude string,\n",
    "\tend_station_longitude string,\n",
    "\tuser_type string,\n",
    "    gender string,\n",
    "\tcustomer_year_birth string,\n",
    "    bike_id string,\n",
    "\trideable_type string,\n",
    "\tstart_at string,\n",
    "\tstop_at string, \n",
    "\ttrip_duration string\n",
    "    )\n",
    "USING iceberg\n",
    "PARTITIONED BY (dw_period_tag)\n",
    ";\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "93abdc4a-7cd9-4aa6-95b3-0a9c80a35544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE TABLE bronze.SylverDw_nybike.trip_data_nybike(\n",
    "    trip_uuid string,\n",
    "    dw_period_tag string,\n",
    "\tstart_station_id string,\n",
    "\tstart_station_name string,\n",
    "\tstart_station_latitude string,\n",
    "\tstart_station_longitude string,\n",
    "\tend_station_id string,\n",
    "\tend_station_name string,\n",
    "\tend_station_latitude string,\n",
    "\tend_station_longitude string,\n",
    "\tbike_id string,\n",
    "\tuser_type string,\n",
    "    enr_user_type string,\n",
    "    enr_gender string,\n",
    "\tcustomer_year_birth  string,\n",
    "\trideable_type string,\n",
    "\tstart_at timestamp,\n",
    "\tstop_at timestamp,\n",
    "\ttrip_duration double,\n",
    "    year integer,\n",
    "    quarter integer,\n",
    "    quarter_name string,\n",
    "    month integer,\n",
    "    month_name string,\n",
    "    day integer,\n",
    "    weekday integer,\n",
    "    weekday_name string\n",
    "    )\n",
    "USING iceberg\n",
    "PARTITIONED BY (dw_period_tag)\n",
    "    ;\n",
    "    \"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2fd06fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spark.sql(\"SHOW tables in bronze.DW_ny_bike;\").show()\n",
    "# spark.sql(\"ALTER TABLE bronze.DW_ny_bike.trip_data_nybike ALTER COLUMN start_at TYPE string;\")\n",
    "# spark.sql(\"DROP TABLE bronze.DW_ny_bike.trip_data_nybike;\")\n",
    "spark.sql(\"TRUNCATE TABLE bronze.SylverDw_nybike.trip_data_nybike;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5272eb08-b01e-473f-a52b-08c16a491c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+----------------+------------------+----------------------+-----------------------+--------------+----------------+--------------------+---------------------+-------+---------+-------------+----------+-------------------+-------------+--------+-------+-------------+----+-------+------------+-----+----------+---+-------+------------+\n",
      "|trip_uuid|dw_period_tag|start_station_id|start_station_name|start_station_latitude|start_station_longitude|end_station_id|end_station_name|end_station_latitude|end_station_longitude|bike_id|user_type|enr_user_type|enr_gender|customer_year_birth|rideable_type|start_at|stop_at|trip_duration|year|quarter|quarter_name|month|month_name|day|weekday|weekday_name|\n",
      "+---------+-------------+----------------+------------------+----------------------+-----------------------+--------------+----------------+--------------------+---------------------+-------+---------+-------------+----------+-------------------+-------------+--------+-------+-------------+----+-------+------------+-----+----------+---+-------+------------+\n",
      "+---------+-------------+----------------+------------------+----------------------+-----------------------+--------------+----------------+--------------------+---------------------+-------+---------+-------------+----------+-------------------+-------------+--------+-------+-------------+----+-------+------------+-----+----------+---+-------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# spark.sql(\"select count(*) from bronze.DW_ny_bike.trip_data_nybike  limit 19;\").show()\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "select \n",
    "    *\n",
    "    --count(*) \n",
    "    --distinct(enr_user_type)\n",
    "from bronze.SylverDw_nybike.trip_data_nybike \n",
    "where \n",
    "    dw_period_tag = '2015'\n",
    "    limit 10\n",
    "    ;\"\"\"\n",
    "         ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c383c563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------+----------------+--------------------+----------------------+-----------------------+--------------+--------------------+--------------------+---------------------+---------+------+-------------------+-------+-------------+--------------------+--------------------+-------------+\n",
      "|dw_period_tag|         ride_id|start_station_id|  start_station_name|start_station_latitude|start_station_longitude|end_station_id|    end_station_name|end_station_latitude|end_station_longitude|user_type|gender|customer_year_birth|bike_id|rideable_type|            start_at|             stop_at|trip_duration|\n",
      "+-------------+----------------+----------------+--------------------+----------------------+-----------------------+--------------+--------------------+--------------------+---------------------+---------+------+-------------------+-------+-------------+--------------------+--------------------+-------------+\n",
      "|       200408|DDF3FD436F128E4E|         8149.09|Ogden Ave & W 165 St|             40.834457|             -73.928381|       8041.07|E 161 St & River Ave|           40.827883|           -73.927111|   member|  NULL|               NULL|   NULL|electric_bike|2024-08-29 15:01:...|2024-08-29 15:05:...|         NULL|\n",
      "|       200408|AFE5DB88E15109EA|         5430.08|Franklin St & W B...|           40.71911552|           -74.00666661|       5470.12|North Moore St & ...|   40.72019521437465|    -74.0103006362915|   member|  NULL|               NULL|   NULL| classic_bike|2024-08-21 18:41:...|2024-08-21 18:48:...|         NULL|\n",
      "|       200408|88F1CE37D662D8E8|         5593.04|      E 4 St & 2 Ave|            40.7262807|           -73.98978041|        5779.1|     E 14 St & 1 Ave|   40.73139303364151|   -73.98286700248718|   member|  NULL|               NULL|   NULL| classic_bike|2024-08-23 19:12:...|2024-08-23 19:16:...|         NULL|\n",
      "|       200408|73D93F3505537785|         5730.08|Greenwich St & W ...|             40.728846|             -74.008591|       5703.13|     Ave A & E 11 St|   40.72854745023944|   -73.98175925016403|   member|  NULL|               NULL|   NULL|electric_bike|2024-08-18 16:45:...|2024-08-18 17:02:...|         NULL|\n",
      "|       200408|28D0FF30828DEAA0|         8218.04|Ogden Ave & Merri...|             40.839142|             -73.925961|       8041.07|E 161 St & River Ave|           40.827883|           -73.927111|   member|  NULL|               NULL|   NULL|electric_bike|2024-08-27 15:49:...|2024-08-27 16:00:...|         NULL|\n",
      "|       200408|5A17C0AC8C2F55EC|         8149.09|Ogden Ave & W 165 St|             40.834457|             -73.928381|       8277.03|Washington Ave & ...|           40.843079|           -73.900216|   member|  NULL|               NULL|   NULL|electric_bike|2024-08-27 08:27:...|2024-08-27 08:41:...|         NULL|\n",
      "|       200408|87343991172AEEB6|         5430.08|Franklin St & W B...|           40.71911552|           -74.00666661|        5779.1|     E 14 St & 1 Ave|   40.73139303364151|   -73.98286700248718|   member|  NULL|               NULL|   NULL|electric_bike|2024-08-28 19:09:...|2024-08-28 19:24:...|         NULL|\n",
      "|       200408|B3E3C9942D973AC0|         8149.09|Ogden Ave & W 165 St|             40.834457|             -73.928381|       8277.03|Washington Ave & ...|           40.843079|           -73.900216|   member|  NULL|               NULL|   NULL|electric_bike|2024-08-30 08:03:...|2024-08-30 08:25:...|         NULL|\n",
      "|       200408|2D881E40E696D7DF|         6667.04|     W 47 St & 6 Ave|             40.758397|              -73.98255|       5769.06|     Ave C & E 16 St|   40.72984830346529|   -73.97455215454102|   member|  NULL|               NULL|   NULL|electric_bike|2024-08-27 11:52:...|2024-08-27 12:06:...|         NULL|\n",
      "|       200408|8AE19AC118EBEE56|         6190.08|     9 Ave & W 18 St|           40.74317449|           -74.00366443|       5703.13|     Ave A & E 11 St|   40.72854745023944|   -73.98175925016403|   member|  NULL|               NULL|   NULL|electric_bike|2024-08-28 18:38:...|2024-08-28 18:51:...|         NULL|\n",
      "|       200408|F13BB747C9285CC7|         5730.08|Greenwich St & W ...|             40.728846|             -74.008591|       5578.02|Watts St & Greenw...|         40.72405549|         -74.00965965|   member|  NULL|               NULL|   NULL|electric_bike|2024-08-19 09:31:...|2024-08-19 09:33:...|         NULL|\n",
      "|       200408|86B47E48BFB28A68|         5593.04|      E 4 St & 2 Ave|            40.7262807|           -73.98978041|        5779.1|     E 14 St & 1 Ave|   40.73139303364151|   -73.98286700248718|   member|  NULL|               NULL|   NULL|electric_bike|2024-08-19 16:53:...|2024-08-19 16:57:...|         NULL|\n",
      "|       200408|3A19A05437BE15EC|         5730.08|Greenwich St & W ...|             40.728846|             -74.008591|       5769.06|     Ave C & E 16 St|   40.72984830346529|   -73.97455215454102|   member|  NULL|               NULL|   NULL| classic_bike|2024-08-27 21:36:...|2024-08-27 21:58:...|         NULL|\n",
      "|       200408|3FF519C91D2E2005|         5001.08|Little West St & ...|           40.70569254|           -74.01677685|       5470.12|North Moore St & ...|   40.72019521437465|    -74.0103006362915|   member|  NULL|               NULL|   NULL| classic_bike|2024-08-16 06:12:...|2024-08-16 06:19:...|         NULL|\n",
      "|       200408|F475DDF35D5C1924|         5593.04|      E 4 St & 2 Ave|            40.7262807|           -73.98978041|        5779.1|     E 14 St & 1 Ave|   40.73139303364151|   -73.98286700248718|   member|  NULL|               NULL|   NULL| classic_bike|2024-08-16 22:04:...|2024-08-16 22:10:...|         NULL|\n",
      "|       200408|F006049EAFE6A8F6|         5001.08|Little West St & ...|           40.70569254|           -74.01677685|       5470.12|North Moore St & ...|   40.72019521437465|    -74.0103006362915|   member|  NULL|               NULL|   NULL| classic_bike|2024-08-18 08:20:...|2024-08-18 08:28:...|         NULL|\n",
      "|       200408|CA22FD4535DFB102|         5001.08|Little West St & ...|           40.70569254|           -74.01677685|       5470.12|North Moore St & ...|   40.72019521437465|    -74.0103006362915|   member|  NULL|               NULL|   NULL|electric_bike|2024-08-16 08:16:...|2024-08-16 08:22:...|         NULL|\n",
      "|       200408|69B6281FF98F9DB3|         5730.08|Greenwich St & W ...|             40.728846|             -74.008591|       5470.12|North Moore St & ...|   40.72019521437465|    -74.0103006362915|   member|  NULL|               NULL|   NULL| classic_bike|2024-08-28 07:31:...|2024-08-28 07:38:...|         NULL|\n",
      "|       200408|9D3D77FCBA82174B|         3460.02|       36 St & 3 Ave|             40.655716|             -74.006664|       4042.08|Underhill Ave & L...|          40.6740123|          -73.9671457|   member|  NULL|               NULL|   NULL|electric_bike|2024-08-31 18:52:...|2024-08-31 19:08:...|         NULL|\n",
      "+-------------+----------------+----------------+--------------------+----------------------+-----------------------+--------------+--------------------+--------------------+---------------------+---------+------+-------------------+-------+-------------+--------------------+--------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# spark.sql(\"select distinct(dw_period_tag) from  bronze.DW_ny_bike.trip_data_nybike limit 19;\").show()\n",
    "spark.sql(\"\"\"\n",
    "select \n",
    "--count(*)\n",
    "*\n",
    "from  bronze.DW_ny_bike.trip_data_nybike \n",
    "where dw_period_tag like '200408%' \n",
    "limit 19;\n",
    "\"\"\").show()\n",
    "# spark.sql(\"DELETE FROM bronze.DW_ny_bike.trip_data_nybike WHERE dw_period_tag='2022';\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60b1961-c06f-4aa5-805a-f7b8dc8a6717",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acf20397",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|             name|\n",
      "+-----------------+\n",
      "|      Alex Merced|\n",
      "|Dipankar Mazumdar|\n",
      "|     Jason Hughes|\n",
      "+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "## Insert Some Data\n",
    "spark.sql(\"INSERT INTO nessie.names VALUES ('Alex Merced'), ('Dipankar Mazumdar'), ('Jason Hughes')\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d2308fd5-e767-42aa-8b69-5649b40153d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------+----------------+--------------------+----------------------+-----------------------+--------------+--------------------+--------------------+---------------------+----------+------+-------------------+-------+-------------+--------+-------+-------------+\n",
      "|dw_period_tag|ride_id|start_station_id|  start_station_name|start_station_latitude|start_station_longitude|end_station_id|    end_station_name|end_station_latitude|end_station_longitude| user_type|gender|customer_year_birth|bike_id|rideable_type|start_at|stop_at|trip_duration|\n",
      "+-------------+-------+----------------+--------------------+----------------------+-----------------------+--------------+--------------------+--------------------+---------------------+----------+------+-------------------+-------+-------------+--------+-------+-------------+\n",
      "|         2014|   NULL|             479|     9 Ave & W 45 St|           40.76019252|            -73.9912551|           540|Lexington Ave & E...|         40.74147286|         -73.98320928|Subscriber|     1|             1977.0|  21376|         NULL|    NULL|   NULL|       1027.0|\n",
      "|         2014|   NULL|             417|Barclay St & Chur...|           40.71291224|           -74.01020234|           417|Barclay St & Chur...|         40.71291224|         -74.01020234|Subscriber|     2|             1974.0|  16086|         NULL|    NULL|   NULL|        534.0|\n",
      "|         2014|   NULL|             327|Vesey Pl & River ...|            40.7153379|           -74.01658354|           415|Pearl St & Hanove...|          40.7047177|         -74.00926027|Subscriber|     1|             1990.0|  16073|         NULL|    NULL|   NULL|        416.0|\n",
      "+-------------+-------+----------------+--------------------+----------------------+-----------------------+--------------+--------------------+--------------------+---------------------+----------+------+-------------------+-------+-------------+--------+-------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Query the Data\n",
    "spark.sql(\"SELECT * FROM nessie.dw_nybike.trip_data_nybike limit 3;\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5e4f1d9-d582-4668-b8d2-7988cce18c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame \n",
    "from typing import Optional\n",
    "from pyspark.sql.functions import lit,concat,to_timestamp,unix_timestamp , from_unixtime ,try_to_timestamp,col,month , udf,isnull ,when\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType , TimestampType , DoubleType , FloatType, DateType,NullType\n",
    "from pyspark.sql import functions as f\n",
    "\n",
    "\n",
    "bronze_schema_ny_bike = StructType([\n",
    "    StructField(\"dw_period_tag\", StringType(), nullable=True),\n",
    "    StructField(\"ride_id\", StringType(), nullable=True),\n",
    "    StructField(\"start_station_id\", StringType(), nullable=True),\n",
    "    StructField(\"start_station_name\", StringType(), nullable=True),\n",
    "    StructField(\"start_station_latitude\", StringType(), nullable=True),\n",
    "    StructField(\"start_station_longitude\", StringType(), nullable=True),\n",
    "    StructField(\"end_station_id\", StringType(), nullable=True),\n",
    "    StructField(\"end_station_name\", StringType(), nullable=True),\n",
    "    StructField(\"end_station_latitude\", StringType(), nullable=True),\n",
    "    StructField(\"end_station_longitude\", StringType(), nullable=True),\n",
    "    StructField(\"bike_id\", StringType(), nullable=True),\n",
    "    StructField(\"user_type\", StringType(), nullable=True),\n",
    "    StructField(\"gender\", StringType(), nullable=True),\n",
    "    StructField(\"customer_year_birth\", StringType(), nullable=True),\n",
    "    StructField(\"rideable_type\", StringType(), nullable=True),\n",
    "    StructField(\"start_at\", StringType(), nullable=True),\n",
    "    StructField(\"stop_at\", StringType(), nullable=True),\n",
    "    StructField(\"trip_duration\", StringType(), nullable=True)\n",
    "])\n",
    "\n",
    "sylver_schema_ny_bike = StructType([\n",
    "    StructField(\"trip_uuid\", StringType(), nullable=True),\n",
    "    StructField(\"dw_period_tag\", StringType(), nullable=True),\n",
    "    StructField(\"start_station_id\", StringType(), nullable=True),\n",
    "    StructField(\"start_station_name\", StringType(), nullable=True),\n",
    "    StructField(\"start_station_latitude\", StringType(), nullable=True),\n",
    "    StructField(\"start_station_longitude\", StringType(), nullable=True),\n",
    "    StructField(\"end_station_id\", StringType(), nullable=True),\n",
    "    StructField(\"end_station_name\", StringType(), nullable=True),\n",
    "    StructField(\"end_station_latitude\", StringType(), nullable=True),\n",
    "    StructField(\"end_station_longitude\", StringType(), nullable=True),\n",
    "    StructField(\"bike_id\", StringType(), nullable=True),\n",
    "    StructField(\"enr_gender\", StringType(), nullable=True),\n",
    "    StructField(\"customer_year_birth\", StringType(), nullable=True),\n",
    "    StructField(\"rideable_type\", StringType(), nullable=True),\n",
    "    StructField(\"start_at\", TimestampType(), nullable=True),\n",
    "    StructField(\"stop_at\", TimestampType(), nullable=True),\n",
    "    StructField(\"trip_duration\", DoubleType(), nullable=True),\n",
    "    StructField(\"user_type\", StringType(), nullable=True),\n",
    "    StructField(\"enr_user_type\", StringType(), nullable=True),\n",
    "    StructField(\"year\", IntegerType(), nullable=True),\n",
    "    StructField(\"quarter\", IntegerType(), nullable=True),\n",
    "    StructField(\"quarter_name\", StringType(), nullable=True),\n",
    "    StructField(\"month\", IntegerType(), nullable=True),\n",
    "    StructField(\"month_name\", StringType(), nullable=True),\n",
    "    StructField(\"day\", IntegerType(), nullable=True),\n",
    "    StructField(\"weekday\", IntegerType(), nullable=True),\n",
    "    StructField(\"weekday_name\", StringType(), nullable=True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c393fc1e-ec73-4a7d-a16b-9233a353dfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "def config_reader(path:str):\n",
    "    # Load YAML config\n",
    "    with open(path, \"r\") as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    return config\n",
    "    \n",
    "def run(df,config):\n",
    "    print(\"Cast To Datamodel initiated\")\n",
    "    data_model_from_df = list(dict(df.dtypes).keys())\n",
    "\n",
    "    filtered_column = list(filter( lambda x: x not in data_model_from_df ,config['schema'].names ))\n",
    "    if len(filtered_column) > 0 :\n",
    "        for column in filtered_column:\n",
    "            df =  df.withColumn(column, lit(None))\n",
    "\n",
    "    df = df.select([\n",
    "        col(field.name).cast(field.dataType).alias(field.name) \n",
    "        for field in config['schema'].fields\n",
    "    ])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d7502a4b-52fe-4de0-b731-cde010db868f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_bike_2015='/opt/airflow/data/2015-citibike-tripdata/1_January/*.csv'\n",
    "# file_bike_2017='/opt/airflow/data/2017-citibike-tripdata/*/*.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "80d02b77-63ff-4114-934c-fa63abb2a060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10_October   12_December  2_February  4_April  6_June  8_August\n",
      "11_November  1_January\t  3_March     5_May    7_July  9_September\n"
     ]
    }
   ],
   "source": [
    "!ls /opt/airflow/data/2015-citibike-tripdata/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8a14fff5-9f09-41d1-b99f-cd58661e34f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> /opt/airflow/data/2015-citibike-tripdata/10_October/201510-citibike-tripdata_1.csv <==\n",
      "tripduration,starttime,stoptime,start station id,start station name,start station latitude,start station longitude,end station id,end station name,end station latitude,end station longitude,bikeid,usertype,birth year,gender\n",
      "171,10/1/2015 00:00:02,10/1/2015 00:02:54,388,W 26 St & 10 Ave,40.749717753,-74.002950346,494,W 26 St & 8 Ave,40.74734825,-73.99723551,24302,Subscriber,1973.0,1\n",
      "593,10/1/2015 00:00:02,10/1/2015 00:09:55,518,E 39 St & 2 Ave,40.74780373,-73.9734419,438,St Marks Pl & 1 Ave,40.72779126,-73.98564945,19904,Subscriber,1990.0,1\n",
      "233,10/1/2015 00:00:11,10/1/2015 00:04:05,447,8 Ave & W 52 St,40.76370739,-73.9851615,447,8 Ave & W 52 St,40.76370739,-73.9851615,17797,Subscriber,1984.0,1\n",
      "250,10/1/2015 00:00:15,10/1/2015 00:04:25,336,Sullivan St & Washington Sq,40.73047747,-73.99906065,223,W 13 St & 7 Ave,40.73781509,-73.99994661,23966,Subscriber,1984.0,1\n",
      "528,10/1/2015 00:00:17,10/1/2015 00:09:05,3107,Bedford Ave & Nassau Ave,40.72311651,-73.95212324,539,Metropolitan Ave & Bedford Ave,40.71534825,-73.96024116,16246,Customer,,0\n",
      "440,10/1/2015 00:00:17,10/1/2015 00:07:37,3107,Bedford Ave & Nassau Ave,40.72311651,-73.95212324,539,Metropolitan Ave & Bedford Ave,40.71534825,-73.96024116,23698,Customer,,0\n",
      "1185,10/1/2015 00:00:22,10/1/2015 00:20:07,531,Forsyth St & Broome St,40.71893904,-73.99266288,3064,Myrtle Ave & Lewis Ave,40.69681963,-73.93756926,17110,Subscriber,1987.0,1\n",
      "618,10/1/2015 00:00:25,10/1/2015 00:10:44,3002,South End Ave & Liberty St,40.711512,-74.015756,2004,6 Ave & Broome St,40.724399,-74.004704,16344,Subscriber,1989.0,1\n",
      "865,10/1/2015 00:00:31,10/1/2015 00:14:57,438,St Marks Pl & 1 Ave,40.72779126,-73.98564945,486,Broadway & W 29 St,40.7462009,-73.98855723,23822,Subscriber,1991.0,2\n",
      "\n",
      "==> /opt/airflow/data/2015-citibike-tripdata/10_October/201510-citibike-tripdata_2.csv <==\n",
      "tripduration,starttime,stoptime,start station id,start station name,start station latitude,start station longitude,end station id,end station name,end station latitude,end station longitude,bikeid,usertype,birth year,gender\n",
      "555,10/26/2015 13:10:10,10/26/2015 13:19:25,480,W 53 St & 10 Ave,40.76669671,-73.99061728,524,W 43 St & 6 Ave,40.75527307,-73.98316936,17359,Subscriber,1988.0,1\n",
      "818,10/26/2015 13:10:19,10/26/2015 13:23:58,281,Grand Army Plaza & Central Park S,40.7643971,-73.97371465,3148,E 84 St & 1 Ave,40.77565541,-73.95068615,19726,Subscriber,1993.0,1\n",
      "400,10/26/2015 13:10:18,10/26/2015 13:16:58,293,Lafayette St & E 8 St,40.73028666,-73.9907647,303,Mercer St & Spring St,40.72362738,-73.99949601,23696,Subscriber,1984.0,1\n",
      "513,10/26/2015 13:10:20,10/26/2015 13:18:53,362,Broadway & W 37 St,40.75172632,-73.98753523,435,W 21 St & 6 Ave,40.74173969,-73.99415556,23812,Subscriber,1979.0,1\n",
      "233,10/26/2015 13:10:21,10/26/2015 13:14:14,3158,W 63 St & Broadway,40.77163851,-73.98261428,468,Broadway & W 55 St,40.7652654,-73.98192338,24045,Subscriber,1987.0,1\n",
      "1081,10/26/2015 13:10:22,10/26/2015 13:28:23,519,Pershing Square North,40.751873,-73.977706,3144,E 81 St & Park Ave,40.77677702,-73.9590097,15974,Subscriber,1984.0,2\n",
      "728,10/26/2015 13:10:26,10/26/2015 13:22:35,447,8 Ave & W 52 St,40.76370739,-73.9851615,3159,W 67 St & Broadway,40.77492513,-73.98266566,19366,Subscriber,1989.0,1\n",
      "277,10/26/2015 13:10:29,10/26/2015 13:15:07,2008,Little West St & 1 Pl,40.70569254,-74.01677685,534,Water - Whitehall Plaza,40.70255065,-74.0127234,20641,Subscriber,1956.0,2\n",
      "268,10/26/2015 13:10:35,10/26/2015 13:15:04,448,W 37 St & 10 Ave,40.75660359,-73.9979009,458,11 Ave & W 27 St,40.751396,-74.005226,23379,Subscriber,1971.0,1\n"
     ]
    }
   ],
   "source": [
    "!head /opt/airflow/data/2015-citibike-tripdata/10_October/*.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40446034-e5c4-41a9-b3e0-44a9d2a3dc75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5439a662-bed2-4c5c-b4d3-1ef5851d63a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\n",
      "SLF4J: Defaulting to no-operation (NOP) logger implementation\n",
      "SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\n"
     ]
    }
   ],
   "source": [
    "# dfinit =spark.read.format('csv').options(inferSchema='True', header='True',delimiter=',').load(file_bike_2015)\n",
    "# df2017 =spark.read.format('csv').options(header='True').load(file_bike_2017)\n",
    "dfinit= spark.sql(\"\"\"SELECT * FROM bronze.DW_ny_bike.trip_data_nybike WHERE dw_period_tag=''; \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbef5c56-bc6d-40e9-9e62-73dd05d999bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfinit_2= spark.sql(\"\"\"SELECT * FROM bronze.DW_ny_bike.trip_data_nybike WHERE dw_period_tag='2015'; \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4004092-6428-45ae-b119-521348bd43f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"SELECT * FROM bronze.DW_ny_bike.trip_data_nybike WHERE dw_period_tag='2015'; \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b9381ef-9b4d-4c42-b4eb-9d9ef9aba355",
   "metadata": {},
   "outputs": [],
   "source": [
    "config=config_reader('config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90c9aad1-77f0-4e05-8643-1efdd9699bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------+----------------+------------------+----------------------+-----------------------+--------------+----------------+--------------------+---------------------+----------+------+-------------------+-------+-------------+--------------+--------------+-------------+\n",
      "|dw_period_tag|ride_id|start_station_id|start_station_name|start_station_latitude|start_station_longitude|end_station_id|end_station_name|end_station_latitude|end_station_longitude| user_type|gender|customer_year_birth|bike_id|rideable_type|      start_at|       stop_at|trip_duration|\n",
      "+-------------+-------+----------------+------------------+----------------------+-----------------------+--------------+----------------+--------------------+---------------------+----------+------+-------------------+-------+-------------+--------------+--------------+-------------+\n",
      "|         2015|   NULL|             499|Broadway & W 60 St|           40.76915505|           -73.98191841|           423| W 54 St & 9 Ave|         40.76584941|         -73.98690506|Subscriber|     1|             1984.0|  15338|         NULL|1/18/2015 0:00|1/18/2015 0:05|          269|\n",
      "|         2015|   NULL|             164|   E 47 St & 2 Ave|           40.75323098|           -73.97032517|          2017| E 43 St & 2 Ave|         40.75022392|         -73.97121414|Subscriber|     1|             1954.0|  19103|         NULL|1/18/2015 0:01|1/18/2015 0:39|         2275|\n",
      "|         2015|   NULL|             529|   W 42 St & 8 Ave|            40.7575699|           -73.99098507|           478|11 Ave & W 41 St|         40.76030096|         -73.99884222|Subscriber|     1|             1981.0|  15653|         NULL|1/18/2015 0:01|1/18/2015 0:05|          223|\n",
      "+-------------+-------+----------------+------------------+----------------------+-----------------------+--------------+----------------+--------------------+---------------------+----------+------+-------------------+-------+-------------+--------------+--------------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dfinit_2.filter(dfinit_2.start_at.like('1/18/2015%')).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c29c3bfd-0f63-4652-b8b2-5fadd8c9392a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------+----------------+--------------------+----------------------+-----------------------+--------------+--------------------+--------------------+---------------------+----------+------+-------------------+-------+-------------+-------------------+-------------------+-------------+\n",
      "|dw_period_tag|ride_id|start_station_id|  start_station_name|start_station_latitude|start_station_longitude|end_station_id|    end_station_name|end_station_latitude|end_station_longitude| user_type|gender|customer_year_birth|bike_id|rideable_type|           start_at|            stop_at|trip_duration|\n",
      "+-------------+-------+----------------+--------------------+----------------------+-----------------------+--------------+--------------------+--------------------+---------------------+----------+------+-------------------+-------+-------------+-------------------+-------------------+-------------+\n",
      "|         2015|   NULL|             497|  E 17 St & Broadway|           40.73704984|           -73.99009296|           518|     E 39 St & 2 Ave|         40.74780373|          -73.9734419|Subscriber|     2|             1979.0|  20184|         NULL|10/16/2015 00:00:06|10/16/2015 00:18:04|         1077|\n",
      "|         2015|   NULL|            3176|W 64 St & West En...|           40.77452835|           -73.98753759|          3175|W 70 St & Amsterd...|         40.77748046|         -73.98288594|Subscriber|     1|             1977.0|  24188|         NULL|10/16/2015 00:00:13|10/16/2015 00:07:21|          427|\n",
      "|         2015|   NULL|             512|     W 29 St & 9 Ave|            40.7500727|           -73.99839279|           536|     1 Ave & E 30 St|         40.74144387|         -73.97536082|Subscriber|     1|             1979.0|  15005|         NULL|10/16/2015 00:00:17|10/16/2015 00:10:52|          634|\n",
      "+-------------+-------+----------------+--------------------+----------------------+-----------------------+--------------+--------------------+--------------------+---------------------+----------+------+-------------------+-------+-------------+-------------------+-------------------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfinit_2.filter(dfinit_2.start_at.like('10/16/2015%')).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "14628d30-8c25-4cda-b234-15b1a0da7eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cast To Datamodel initiated\n"
     ]
    }
   ],
   "source": [
    "config={'schema':sylver_schema_ny_bike}\n",
    "df_casted = run(dfinit,config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "66377814-979a-48f0-93dc-eb209c60c9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- trip_uuid: string (nullable = true)\n",
      " |-- dw_period_tag: string (nullable = true)\n",
      " |-- start_station_id: string (nullable = true)\n",
      " |-- start_station_name: string (nullable = true)\n",
      " |-- start_station_latitude: string (nullable = true)\n",
      " |-- start_station_longitude: string (nullable = true)\n",
      " |-- end_station_id: string (nullable = true)\n",
      " |-- end_station_name: string (nullable = true)\n",
      " |-- end_station_latitude: string (nullable = true)\n",
      " |-- end_station_longitude: string (nullable = true)\n",
      " |-- bike_id: integer (nullable = true)\n",
      " |-- enr_gender: string (nullable = true)\n",
      " |-- customer_year_birth: string (nullable = true)\n",
      " |-- rideable_type: string (nullable = true)\n",
      " |-- start_at: timestamp (nullable = true)\n",
      " |-- stop_at: timestamp (nullable = true)\n",
      " |-- trip_duration: double (nullable = true)\n",
      " |-- customer_type: string (nullable = true)\n",
      " |-- quarter: integer (nullable = true)\n",
      " |-- quarter_name: string (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- month_name: string (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- weekday: integer (nullable = true)\n",
      " |-- weekday_name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_casted.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "729fbeaf-9e5b-4ec7-8ecc-7adc1f1b6a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_casted.select('*').when(isnull('start_at')).show(10)\n",
    "# df_casted.filter(month(col('start_at')) ==  ).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5522375-0652-4559-b55c-781e780bff57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- trip_duration: integer (nullable = true)\n",
      " |-- start_at: string (nullable = true)\n",
      " |-- stop_at: string (nullable = true)\n",
      " |-- start_station_id: integer (nullable = true)\n",
      " |-- start_station_name: string (nullable = true)\n",
      " |-- start_station_latitude: double (nullable = true)\n",
      " |-- start_station_longitude: double (nullable = true)\n",
      " |-- end_station_id: integer (nullable = true)\n",
      " |-- end_station_name: string (nullable = true)\n",
      " |-- end_station_latitude: double (nullable = true)\n",
      " |-- end_station_longitude: double (nullable = true)\n",
      " |-- bike_id: integer (nullable = true)\n",
      " |-- user_type: string (nullable = true)\n",
      " |-- customer_year_birth: string (nullable = true)\n",
      " |-- gender: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_renamed.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fabd9d38-e317-41fa-89ce-a960461408d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfconverted = df.to(bronze_schema_ny_bike)\n",
    "# df.select(df.start_at.cast(\"TIMESTAMP\").alias('start_at')).show()\n",
    "# df.select(to_timestamp(df.start_at, 'MM/dd/yyyy HH:mm:ss')).show(5)\n",
    "# df.select(from_unixtime(unix_timestamp('start_at', 'MM/dd/yyyy HH:mm:ss')).cast(TimestampType()).alias(\"timestamp\")).show(5)\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import unix_timestamp, from_unixtime,to_timestamp,udf\n",
    "\n",
    "# df_renamed_v2 = df_renamed.select(from_unixtime(unix_timestamp('start_at', 'MM/dd/yyyy hh:mm:ss ')).cast(TimestampType()).alias(\"timestamp\"))\n",
    "# change timestamp format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2327764-65ab-43c3-bb52-6c66c3efac10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_renamed_v2 = df_renamed.withColumn(\"timestamp\", to_timestamp(\"start_at\", \"d/M/yyyy HH:mm:ss\"))\n",
    "# df = df.withColumn(\"timestamp\", to_timestamp(df[\"date_string\"], \"M/d/yyyy HH:mm:ss\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "aedc22bb-1459-41f4-9141-9cd9827ca3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- trip_uuid: string (nullable = true)\n",
      " |-- dw_period_tag: string (nullable = true)\n",
      " |-- start_station_id: string (nullable = true)\n",
      " |-- start_station_name: string (nullable = true)\n",
      " |-- start_station_latitude: string (nullable = true)\n",
      " |-- start_station_longitude: string (nullable = true)\n",
      " |-- end_station_id: string (nullable = true)\n",
      " |-- end_station_name: string (nullable = true)\n",
      " |-- end_station_latitude: string (nullable = true)\n",
      " |-- end_station_longitude: string (nullable = true)\n",
      " |-- bike_id: integer (nullable = true)\n",
      " |-- enr_gender: string (nullable = true)\n",
      " |-- customer_year_birth: string (nullable = true)\n",
      " |-- rideable_type: string (nullable = true)\n",
      " |-- start_at: timestamp (nullable = true)\n",
      " |-- stop_at: timestamp (nullable = true)\n",
      " |-- trip_duration: double (nullable = true)\n",
      " |-- customer_type: string (nullable = true)\n",
      " |-- quarter: integer (nullable = true)\n",
      " |-- quarter_name: string (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- month_name: string (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- weekday: integer (nullable = true)\n",
      " |-- weekday_name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_casted.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "4827c74a-c2b9-4780-afde-07f8dce7d981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2014, 10, 1, 0, 0, 27)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "inDate = \"10/1/2014 00:00:27\"\n",
    "d = datetime.strptime(inDate, \"%m/%d/%Y %H:%M:%S\")\n",
    "d\n",
    "# strdate = d.strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "b8e2c462-a7fe-4b65-81d5-4e59d9a377e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_guis=  d.strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "2e9f4863-6a9e-4e67-a5d6-7c809d22e59e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(str_guis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21586738-a80b-47fc-a1c6-a47bf6b2365d",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.datetime(2013, 4, 29, 15, 59, 2)\n",
    "d.strftime(\"YYYYMMDD HH:mm:ss (%Y%m%d %H:%M:%S)\")\n",
    "'YYYYMMDD HH:mm:ss (20130429 15:59:02)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "3d4ed6c7-3eaf-4587-94de-944a0602723d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert_udf = udf( lambda date: to_timestamp (datetime.strptime(date,'%m/%d/%Y %H:%M:%S'),TimestampType()))\n",
    "convert_udf = udf( lambda date: to_timestamp (col((datetime.strptime(date,'%m/%d/%Y %H:%M:%S').strftime(\"%Y-%m-%d %H:%M:%S\"),TimestampType()))))\n",
    "\n",
    "@udf\n",
    "def convert_to_timestam(date_in):\n",
    "    str_date = datetime.strptime(date_in,'%m/%d/%Y %H:%M:%S').strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    # col_date = col(str_date)\n",
    "    # return to_timestamp(col_date)\n",
    "    return str_date\n",
    "\n",
    "@udf\n",
    "def convert_v2(date_in):\n",
    "    date_datetime_format = datetime.strptime(date_in,'%m/%d/%Y %H:%M:%S') \n",
    "    str_date = date_datetime_format.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    return str_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "a0136afa-3d31-41f5-bd20-470b3fa639ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+------------------+----------------+--------------------+----------------------+-----------------------+--------------+--------------------+--------------------+---------------------+------+----------+----------+------+\n",
      "|tripduration|         starttime|          stoptime|start station id|  start station name|start station latitude|start station longitude|end station id|    end station name|end station latitude|end station longitude|bikeid|  usertype|birth year|gender|\n",
      "+------------+------------------+------------------+----------------+--------------------+----------------------+-----------------------+--------------+--------------------+--------------------+---------------------+------+----------+----------+------+\n",
      "|        1027|10/1/2014 00:00:27|10/1/2014 00:17:34|             479|     9 Ave & W 45 St|           40.76019252|            -73.9912551|           540|Lexington Ave & E...|         40.74147286|         -73.98320928| 21376|Subscriber|    1977.0|     1|\n",
      "|         534|10/1/2014 00:00:36|10/1/2014 00:09:30|             417|Barclay St & Chur...|           40.71291224|           -74.01020234|           417|Barclay St & Chur...|         40.71291224|         -74.01020234| 16086|Subscriber|    1974.0|     2|\n",
      "+------------+------------------+------------------+----------------+--------------------+----------------------+-----------------------+--------------+--------------------+--------------------+---------------------+------+----------+----------+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dfinit.printSchema()\n",
    "dfinit.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e01bd45-c68a-44c7-ab91-8a5fc6064c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import coalesce,lit,concat,to_timestamp,unix_timestamp , from_unixtime ,try_to_timestamp,col,month , udf,isnull ,when,cast,to_timestamp\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType , TimestampType , DoubleType , FloatType, DateType,NullType\n",
    "from pyspark.sql import functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "fea40570-664d-4832-9542-e5dda81bd090",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_1=dfinit.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "7965f7c1-d262-459f-a0ad-005c9e52269c",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_start = row_1['starttime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "66b0cd87-3975-4b45-b092-bca6e19afc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_startime = convert_v2(row_1['starttime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "549f188b-f144-4e7c-8d46-6b6da8bea83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------+----------------+------------------+----------------------+-----------------------+--------------+--------------------+--------------------+---------------------+----------+------+-------------------+-------+-------------+-------------+-------------+-------------+\n",
      "|dw_period_tag|ride_id|start_station_id|start_station_name|start_station_latitude|start_station_longitude|end_station_id|    end_station_name|end_station_latitude|end_station_longitude| user_type|gender|customer_year_birth|bike_id|rideable_type|     start_at|      stop_at|trip_duration|\n",
      "+-------------+-------+----------------+------------------+----------------------+-----------------------+--------------+--------------------+--------------------+---------------------+----------+------+-------------------+-------+-------------+-------------+-------------+-------------+\n",
      "|         2015|   NULL|             455|   1 Ave & E 44 St|           40.75001986|           -73.96905301|           265|Stanton St & Chry...|         40.72229346|         -73.99147535|Subscriber|     2|             1960.0|  18660|         NULL|1/1/2015 0:01|1/1/2015 0:24|         1346|\n",
      "+-------------+-------+----------------+------------------+----------------------+-----------------------+--------------+--------------------+--------------------+---------------------+----------+------+-------------------+-------+-------------+-------------+-------------+-------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfinit_2.filter(dfinit_2.start_at.like('1/1/2015%')).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae83f283-c8a5-4eab-9b4b-1f3df8cea840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfinit.select(convert_to_timestam(\"starttime\").alias(\"start_time\").cast(TimestampType())).printSchema()\n",
    "# dfinit.withColumn('starttime',convert_to_timestam(\"starttime\").cast(TimestampType())).printSchema()\n",
    "# dfinit.withColumn('start_at',when(to_timestamp(dfinit.start_at).isNotNull(),to_timestamp(dfinit.start_at)).when(convert_v2(col(\"start_at\")).isNotNull(),convert_v2(col(\"start_at\")))).show(2)\n",
    "# dfinit.withColumn('starttime',convert_v2('starttime')).withColumn('starttime',to_timestamp('starttime','yyyy-MM-dd HH:mm:ss')).printSchema()\n",
    "\n",
    "# dfinit.withColumn('starttime',when(to_timestamp(dfinit.starttime).isNotNull(),to_timestamp(dfinit.starttime)).when(convert_v2(col(\"starttime\")).isNotNull(),convert_v2(col(\"starttime\")))).withColumn('starttime',to_timestamp('starttime')).show(1)\n",
    "\n",
    "\n",
    "# dfinit.withColumn('starttime',to_timestamp(col('starttime'),'MM/d/yyyy HH:mm:ss')).filter(dfinit.starttime,isNull()).collect().show(1)\n",
    "# dfinit.withColumn('start_at',df['']('starttime')).show(1)\n",
    "\n",
    "# regex_pattern = r\"^\\d{1,2}/\\d{1,2}/\\d{4} \\d{2}:\\d{2}:\\d{2}$\"\n",
    "# regex_pattern = r\"^\\d{1,2}/\\d{1,2}/\\d{4} \\d{2}:\\d{2}$\"\n",
    "\n",
    "regex_pattern = r\"^\\d{1,2}/\\d{1,2}/\\d{4} \\d{1,2}:\\d{2}$\"\n",
    "column='start_at'\n",
    "\n",
    "dfinit_3=dfinit_2\\\n",
    ".filter(dfinit_2.start_at.like('1/%/2015%'))\\\n",
    ".withColumn(column,when(col(column).rlike(regex_pattern),concat(col(column),lit(':00'))).otherwise(col(column))) \\\n",
    "\n",
    "\n",
    "# .withColumn(\n",
    "#     \"enr_starttime\",\n",
    "#     coalesce(\n",
    "#         # to_timestamp(col(column), 'M/d/yyyy HH:mm:ss')\n",
    "#         to_timestamp(col(column), 'MM/d/yyyy H:mm:ss'),\n",
    "#         to_timestamp(col(column), \"yyyy-MM-dd HH:mm:ss\"),\n",
    "#         to_timestamp(col(column))\n",
    "#     )\n",
    "# ).show(1)\n",
    "\n",
    "# dfinit.filter(dfinit.start_at.like('1/1/2015%')).withColumn(\"enr_starttime\",when(col('start_at').rlike(regex_pattern),concat(col('start_at'),lit(':00'))).otherwise(col('start_at'))).show(3)\n",
    "\n",
    "# dfinit.withColumn(\n",
    "#     \"enr_starttime\",\n",
    "#     when( col('starttime').rlike(regex_pattern),to_timestamp(col('starttime'))\n",
    "#         col('starttime').rlike(regex_pattern)\n",
    "# ).show(3)\n",
    "\n",
    "# dfinit.withColumn('starttime',to_timestamp(col('starttime'),'MM/d/yyyy HH:mm:ss')).filter(dfinit.starttime.isNull()).collect()\n",
    "# col(\"date_string\").rlike(regex_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3976814-5710-4bff-93cc-3871d81ead72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:===================>                                       (1 + 2) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------+----------------+------------------+----------------------+-----------------------+--------------+--------------------+--------------------+---------------------+----------+------+-------------------+-------+-------------+----------------+-------------+-------------+\n",
      "|dw_period_tag|ride_id|start_station_id|start_station_name|start_station_latitude|start_station_longitude|end_station_id|    end_station_name|end_station_latitude|end_station_longitude| user_type|gender|customer_year_birth|bike_id|rideable_type|        start_at|      stop_at|trip_duration|\n",
      "+-------------+-------+----------------+------------------+----------------------+-----------------------+--------------+--------------------+--------------------+---------------------+----------+------+-------------------+-------+-------------+----------------+-------------+-------------+\n",
      "|         2015|   NULL|             455|   1 Ave & E 44 St|           40.75001986|           -73.96905301|           265|Stanton St & Chry...|         40.72229346|         -73.99147535|Subscriber|     2|             1960.0|  18660|         NULL|1/1/2015 0:01:00|1/1/2015 0:24|         1346|\n",
      "+-------------+-------+----------------+------------------+----------------------+-----------------------+--------------+--------------------+--------------------+---------------------+----------+------+-------------------+-------+-------------+----------------+-------------+-------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dfinit_3.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "269c5657-3a62-4b36-97ee-ddd249435be7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `M/d/yyyy HH:mm:ss` cannot be resolved. Did you mean one of the following? [`start_at`, `bronze`.`DW_ny_bike`.`trip_data_nybike`.`gender`, `bronze`.`DW_ny_bike`.`trip_data_nybike`.`stop_at`, `bronze`.`DW_ny_bike`.`trip_data_nybike`.`bike_id`, `bronze`.`DW_ny_bike`.`trip_data_nybike`.`ride_id`].;\n'Project [dw_period_tag#49, ride_id#50, start_station_id#51, start_station_name#52, start_station_latitude#53, start_station_longitude#54, end_station_id#55, end_station_name#56, end_station_latitude#57, end_station_longitude#58, user_type#59, gender#60, customer_year_birth#61, bike_id#62, rideable_type#63, start_at#181, stop_at#65, trip_duration#66, coalesce(safe_to_timestamp(start_at#181, 'M/d/yyyy HH:mm:ss)#876, safe_to_timestamp(start_at#181, 'M/d/yyyy H:mm:ss)#877) AS enr_starttime#878]\n+- Filter start_at#181 LIKE 1/%/2015%\n   +- Project [dw_period_tag#49, ride_id#50, start_station_id#51, start_station_name#52, start_station_latitude#53, start_station_longitude#54, end_station_id#55, end_station_name#56, end_station_latitude#57, end_station_longitude#58, user_type#59, gender#60, customer_year_birth#61, bike_id#62, rideable_type#63, CASE WHEN RLIKE(start_at#64, ^\\d{1,2}/\\d{1,2}/\\d{4} \\d{1,2}:\\d{2}$) THEN concat(start_at#64, :00) ELSE start_at#64 END AS start_at#181, stop_at#65, trip_duration#66]\n      +- Filter start_at#64 LIKE 1/%/2015%\n         +- Project [dw_period_tag#49, ride_id#50, start_station_id#51, start_station_name#52, start_station_latitude#53, start_station_longitude#54, end_station_id#55, end_station_name#56, end_station_latitude#57, end_station_longitude#58, user_type#59, gender#60, customer_year_birth#61, bike_id#62, rideable_type#63, start_at#64, stop_at#65, trip_duration#66]\n            +- Filter (dw_period_tag#49 = 2015)\n               +- SubqueryAlias bronze.DW_ny_bike.trip_data_nybike\n                  +- RelationV2[dw_period_tag#49, ride_id#50, start_station_id#51, start_station_name#52, start_station_latitude#53, start_station_longitude#54, end_station_id#55, end_station_name#56, end_station_latitude#57, end_station_longitude#58, user_type#59, gender#60, customer_year_birth#61, bike_id#62, rideable_type#63, start_at#64, stop_at#65, trip_duration#66] bronze.DW_ny_bike.trip_data_nybike bronze.DW_ny_bike.trip_data_nybike\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 17\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError occurred: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m columnv2\n\u001b[1;32m     15\u001b[0m \u001b[43mdfinit_3\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdfinit_3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_at\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlike\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m1/\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m/2015\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwithColumn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43menr_starttime\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoalesce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43msafe_to_timestamp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mM/d/yyyy HH:mm:ss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43msafe_to_timestamp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mM/d/yyyy H:mm:ss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# to_timestamp(col(column), 'M/d/yyyy H:mm:ss')\u001b[39;49;00m\n\u001b[1;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# to_timestamp(col(column), 'MM/dd/yyyy H:mm:ss')\u001b[39;49;00m\n\u001b[1;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# to_timestamp(col(column), 'MM/dd/yyyy H:mm:ss')\u001b[39;49;00m\n\u001b[1;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# to_timestamp(col(column), \"yyyy-MM-dd HH:mm:ss\"),\u001b[39;49;00m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# to_timestamp(col(column))\u001b[39;49;00m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshow(\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/sql/dataframe.py:5176\u001b[0m, in \u001b[0;36mDataFrame.withColumn\u001b[0;34m(self, colName, col)\u001b[0m\n\u001b[1;32m   5171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col, Column):\n\u001b[1;32m   5172\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[1;32m   5173\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_COLUMN\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5174\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(col)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[1;32m   5175\u001b[0m     )\n\u001b[0;32m-> 5176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwithColumn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolName\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jc\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparkSession)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `M/d/yyyy HH:mm:ss` cannot be resolved. Did you mean one of the following? [`start_at`, `bronze`.`DW_ny_bike`.`trip_data_nybike`.`gender`, `bronze`.`DW_ny_bike`.`trip_data_nybike`.`stop_at`, `bronze`.`DW_ny_bike`.`trip_data_nybike`.`bike_id`, `bronze`.`DW_ny_bike`.`trip_data_nybike`.`ride_id`].;\n'Project [dw_period_tag#49, ride_id#50, start_station_id#51, start_station_name#52, start_station_latitude#53, start_station_longitude#54, end_station_id#55, end_station_name#56, end_station_latitude#57, end_station_longitude#58, user_type#59, gender#60, customer_year_birth#61, bike_id#62, rideable_type#63, start_at#181, stop_at#65, trip_duration#66, coalesce(safe_to_timestamp(start_at#181, 'M/d/yyyy HH:mm:ss)#876, safe_to_timestamp(start_at#181, 'M/d/yyyy H:mm:ss)#877) AS enr_starttime#878]\n+- Filter start_at#181 LIKE 1/%/2015%\n   +- Project [dw_period_tag#49, ride_id#50, start_station_id#51, start_station_name#52, start_station_latitude#53, start_station_longitude#54, end_station_id#55, end_station_name#56, end_station_latitude#57, end_station_longitude#58, user_type#59, gender#60, customer_year_birth#61, bike_id#62, rideable_type#63, CASE WHEN RLIKE(start_at#64, ^\\d{1,2}/\\d{1,2}/\\d{4} \\d{1,2}:\\d{2}$) THEN concat(start_at#64, :00) ELSE start_at#64 END AS start_at#181, stop_at#65, trip_duration#66]\n      +- Filter start_at#64 LIKE 1/%/2015%\n         +- Project [dw_period_tag#49, ride_id#50, start_station_id#51, start_station_name#52, start_station_latitude#53, start_station_longitude#54, end_station_id#55, end_station_name#56, end_station_latitude#57, end_station_longitude#58, user_type#59, gender#60, customer_year_birth#61, bike_id#62, rideable_type#63, start_at#64, stop_at#65, trip_duration#66]\n            +- Filter (dw_period_tag#49 = 2015)\n               +- SubqueryAlias bronze.DW_ny_bike.trip_data_nybike\n                  +- RelationV2[dw_period_tag#49, ride_id#50, start_station_id#51, start_station_name#52, start_station_latitude#53, start_station_longitude#54, end_station_id#55, end_station_name#56, end_station_latitude#57, end_station_longitude#58, user_type#59, gender#60, customer_year_birth#61, bike_id#62, rideable_type#63, start_at#64, stop_at#65, trip_duration#66] bronze.DW_ny_bike.trip_data_nybike bronze.DW_ny_bike.trip_data_nybike\n"
     ]
    }
   ],
   "source": [
    "regex_pattern = r\"^\\d{1,2}/\\d{1,2}/\\d{4} \\d{1,2}:\\d{2}$\"\n",
    "# .filter(dfinit.start_at.rlike('1/%/2015% __:__:__'))\\\n",
    "\n",
    "@udf\n",
    "def safe_to_timestamp(column, fmt):\n",
    "    columnv2 = None\n",
    "    try:\n",
    "        columnv2 = when(to_timestamp(col(column), fmt).isNotNull(), to_timestamp(col(column), fmt)).otherwise(None)\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "    return columnv2\n",
    "\n",
    "\n",
    "\n",
    "dfinit_3\\\n",
    ".filter(dfinit_3.start_at.like('1/%/2015%'))\\\n",
    ".withColumn(\n",
    "    \"enr_starttime\",\n",
    "    coalesce(\n",
    "        safe_to_timestamp(col(column), 'M/d/yyyy HH:mm:ss'),\n",
    "        safe_to_timestamp(col(column),'M/d/yyyy H:mm:ss')\n",
    "        # to_timestamp(col(column), 'M/d/yyyy H:mm:ss')\n",
    "        # to_timestamp(col(column), 'MM/dd/yyyy H:mm:ss')\n",
    "        # to_timestamp(col(column), 'MM/dd/yyyy H:mm:ss')\n",
    "        # to_timestamp(col(column), \"yyyy-MM-dd HH:mm:ss\"),\n",
    "        # to_timestamp(col(column))\n",
    "    )\n",
    ").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89da5f37-6f11-4b92-b280-53ec7206c0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Create DataFrame\n",
    "    df = spark.createDataFrame(data, schema=schema)\n",
    "    # Convert string dates to actual DateType\n",
    "    df = df.withColumn(\"startDate\", to_date(col(\"startDate\"), \"yyyy-MM-dd\")) \\\n",
    "           .withColumn(\"endDate\", to_date(col(\"endDate\"), \"yyyy-MM-dd\"))\n",
    "    # Show the DataFrame\n",
    "    df.show()\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
